{
  "properties": {
    "id": {
      "type": "string",
      "description": "The unique ID of the response that was created."
    },
    "object": {
      "type": "string",
      "enum": ["response"],
      "description": "The object type, which was always `response`.",
      "default": "response",
      "x-stainless-const": true
    },
    "created_at": {
      "type": "integer",
      "description": "The Unix timestamp (in seconds) for when the response was created."
    },
    "completed_at": {
      "anyOf": [
        {
          "type": "integer",
          "description": "The Unix timestamp (in seconds) for when the response was completed, if it was completed."
        },
        {
          "type": "null"
        }
      ]
    },
    "status": {
      "type": "string",
      "description": "The status that was set for the response."
    },
    "incomplete_details": {
      "anyOf": [
        {
          "$ref": "./IncompleteDetails.json",
          "description": "Details about why the response was incomplete, if applicable."
        },
        {
          "type": "null"
        }
      ]
    },
    "model": {
      "type": "string",
      "description": "The model that generated this response."
    },
    "previous_response_id": {
      "anyOf": [
        {
          "type": "string",
          "description": "The ID of the previous response in the chain that was referenced, if any."
        },
        {
          "type": "null"
        }
      ]
    },
    "next_response_ids": {
      "items": {
        "type": "string"
      },
      "type": "array",
      "description": "The IDs of responses that were created as follow-ups to this response, if requested."
    },
    "instructions": {
      "anyOf": [
        {
          "oneOf": [
            {
              "type": "string"
            },
            {
              "items": {
                "$ref": "./PromptInstructionMessage.json"
              },
              "type": "array"
            }
          ],
          "description": "Additional instructions that were used to guide the model for this response."
        },
        {
          "type": "null"
        }
      ]
    },
    "input": {
      "items": {
        "$ref": "./ItemField.json"
      },
      "type": "array",
      "description": "The input items that were provided to the model."
    },
    "output": {
      "items": {
        "$ref": "./ItemField.json"
      },
      "type": "array",
      "description": "The output items that were generated by the model."
    },
    "error": {
      "anyOf": [
        {
          "$ref": "./Error.json",
          "description": "The error that occurred, if the response failed."
        },
        {
          "type": "null"
        }
      ]
    },
    "tools": {
      "items": {
        "$ref": "./Tool.json"
      },
      "type": "array",
      "description": "The tools that were available to the model during response generation."
    },
    "tool_choice": {
      "oneOf": [
        {
          "oneOf": [
            {
              "$ref": "./CodeInterpreterToolChoice.json"
            },
            {
              "$ref": "./FunctionToolChoice.json"
            },
            {
              "$ref": "./MCPToolChoice.json"
            },
            {
              "$ref": "./FileSearchToolChoice.json"
            },
            {
              "$ref": "./WebSearchToolChoice.json"
            },
            {
              "$ref": "./ImageGenToolChoice.json"
            },
            {
              "$ref": "./ComputerToolChoice.json"
            },
            {
              "$ref": "./LocalShellToolChoice.json"
            },
            {
              "$ref": "./FunctionShellToolChoice.json"
            },
            {
              "$ref": "./ApplyPatchToolChoice.json"
            },
            {
              "$ref": "./CustomToolChoice.json"
            }
          ]
        },
        {
          "$ref": "./ToolChoiceValueEnum.json"
        },
        {
          "$ref": "./AllowedToolChoice.json"
        }
      ]
    },
    "truncation": {
      "$ref": "./TruncationEnum.json",
      "description": "How the input was truncated by the service when it exceeded the model context window."
    },
    "parallel_tool_calls": {
      "type": "boolean",
      "description": "Whether the model was allowed to call multiple tools in parallel."
    },
    "text": {
      "$ref": "./TextField.json",
      "description": "Configuration options for text output that were used."
    },
    "top_p": {
      "type": "number",
      "description": "The nucleus sampling parameter that was used for this response."
    },
    "presence_penalty": {
      "type": "number",
      "description": "The presence penalty that was used to penalize new tokens based on whether they appear in the text so far."
    },
    "frequency_penalty": {
      "type": "number",
      "description": "The frequency penalty that was used to penalize new tokens based on their frequency in the text so far."
    },
    "top_logprobs": {
      "type": "integer",
      "description": "The number of most likely tokens that were returned at each position, along with their log probabilities."
    },
    "temperature": {
      "type": "number",
      "description": "The sampling temperature that was used for this response."
    },
    "reasoning": {
      "anyOf": [
        {
          "$ref": "./Reasoning.json",
          "description": "Reasoning configuration and outputs that were produced for this response."
        },
        {
          "type": "null"
        }
      ]
    },
    "user": {
      "anyOf": [
        {
          "type": "string",
          "description": "A unique identifier that was used to represent your end user."
        },
        {
          "type": "null"
        }
      ]
    },
    "usage": {
      "anyOf": [
        {
          "$ref": "./Usage.json",
          "description": "Token usage statistics that were recorded for the response, if available."
        },
        {
          "type": "null"
        }
      ]
    },
    "cost_token": {
      "type": "string",
      "description": "A signed token that was generated to encode usage and cost information for this response."
    },
    "max_output_tokens": {
      "anyOf": [
        {
          "type": "integer",
          "description": "The maximum number of tokens the model was allowed to generate for this response."
        },
        {
          "type": "null"
        }
      ]
    },
    "max_tool_calls": {
      "anyOf": [
        {
          "type": "integer",
          "description": "The maximum number of tool calls the model was allowed to make while generating the response."
        },
        {
          "type": "null"
        }
      ]
    },
    "store": {
      "type": "boolean",
      "description": "Whether this response was stored so it can be retrieved later."
    },
    "background": {
      "type": "boolean",
      "description": "Whether this request was run in the background."
    },
    "service_tier": {
      "type": "string",
      "description": "The service tier that was used for this response."
    },
    "context_edits": {
      "items": {
        "$ref": "./ContextEdit.json"
      },
      "type": "array",
      "description": "The context management edits that were applied while generating this response, if any."
    },
    "metadata": {
      "$ref": "./MetadataParam.json",
      "description": "Developer-defined metadata that was associated with the response."
    },
    "safety_identifier": {
      "anyOf": [
        {
          "type": "string",
          "description": "A stable identifier that was used for safety monitoring and abuse detection."
        },
        {
          "type": "null"
        }
      ]
    },
    "prompt_cache_key": {
      "anyOf": [
        {
          "type": "string",
          "description": "A key that was used to read from or write to the prompt cache."
        },
        {
          "type": "null"
        }
      ]
    },
    "prompt_cache_retention": {
      "anyOf": [
        {
          "$ref": "./PromptCacheRetentionEnum.json",
          "description": "How long a prompt cache entry created by this request was retained."
        },
        {
          "type": "null"
        }
      ]
    },
    "conversation": {
      "anyOf": [
        {
          "$ref": "./Conversation.json",
          "description": "The conversation that this response was associated with, if any."
        },
        {
          "type": "null"
        }
      ]
    },
    "billing": {
      "$ref": "./Billing.json",
      "description": "Billing information that was recorded for the response, if available."
    }
  },
  "type": "object",
  "required": [
    "id",
    "object",
    "created_at",
    "completed_at",
    "status",
    "incomplete_details",
    "model",
    "previous_response_id",
    "instructions",
    "output",
    "error",
    "tools",
    "tool_choice",
    "truncation",
    "parallel_tool_calls",
    "text",
    "top_p",
    "presence_penalty",
    "frequency_penalty",
    "top_logprobs",
    "temperature",
    "reasoning",
    "user",
    "usage",
    "max_output_tokens",
    "max_tool_calls",
    "store",
    "background",
    "service_tier",
    "metadata",
    "safety_identifier",
    "prompt_cache_key"
  ],
  "title": "The response object",
  "description": "The complete response object that was returned by the Responses API.",
  "example": {
    "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
    "object": "response",
    "created_at": 1741476777,
    "status": "completed",
    "completed_at": 1741476778,
    "model": "gpt-4o-2024-08-06",
    "output": [
      {
        "type": "message",
        "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
        "status": "completed",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
            "annotations": []
          }
        ]
      }
    ],
    "parallel_tool_calls": true,
    "reasoning": {},
    "store": true,
    "background": false,
    "temperature": 1,
    "presence_penalty": 0,
    "frequency_penalty": 0,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": {
      "input_tokens": 328,
      "input_tokens_details": {
        "cached_tokens": 0
      },
      "output_tokens": 52,
      "output_tokens_details": {
        "reasoning_tokens": 0
      },
      "total_tokens": 380
    },
    "metadata": {},
    "service_tier": "default",
    "top_logprobs": 0
  },
  "x-openai-class-name": "responsesapi.api.resources.response_resource.ResponseBody"
}
